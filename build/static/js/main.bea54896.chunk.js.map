{"version":3,"sources":["utilities.js","App.js","index.js"],"names":["speak","text","utterance","SpeechSynthesisUtterance","window","speechSynthesis","stopSpeech","cancel","App","webcamRef","useRef","canvasRef","lastDetectedObject","setLastDetectedObject","useState","cameraFacingMode","setCameraFacingMode","detect","async","current","video","readyState","videoWidth","videoHeight","width","height","obj","net","drawRect","detections","ctx","detectionsPresent","forEach","prediction","x","y","color","Math","floor","random","toString","strokeStyle","font","beginPath","fillStyle","fillText","rect","stroke","getContext","detectedObjectName","length","class","startCamera","console","log","facingMode","devices","navigator","mediaDevices","enumerateDevices","selectedDeviceId","device","kind","label","includes","deviceId","constraints","exact","undefined","some","stream","getUserMedia","srcObject","error","alert","useEffect","cocossd","setInterval","runCoco","React","createElement","className","Webcam","ref","muted","style","position","marginLeft","marginRight","left","right","textAlign","zindex","maxWidth","top","bottom","transform","padding","borderRadius","onClick","switchCamera","newFacingMode","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"4XAEO,MAAMA,EAASC,IACpB,MAAMC,EAAY,IAAIC,yBAAyBF,GAC/CG,OAAOC,gBAAgBL,MAAME,IAuCzBI,EAAaA,KACjBF,OAAOC,gBAAgBE,UCoJVC,MApLf,WACE,MAAMC,EAAYC,iBAAO,MACnBC,EAAYD,iBAAO,OAClBE,EAAoBC,GAAyBC,mBAAS,OACtDC,EAAkBC,GAAuBF,mBAAS,eAcnDG,EAASC,UAEb,GAC+B,qBAAtBT,EAAUU,SACK,OAAtBV,EAAUU,SAC6B,IAAvCV,EAAUU,QAAQC,MAAMC,WACxB,CAEA,MAAMD,EAAQX,EAAUU,QAAQC,MAC1BE,EAAab,EAAUU,QAAQC,MAAME,WACrCC,EAAcd,EAAUU,QAAQC,MAAMG,YAG5Cd,EAAUU,QAAQC,MAAMI,MAAQF,EAChCb,EAAUU,QAAQC,MAAMK,OAASF,EAGjCZ,EAAUQ,QAAQK,MAAQF,EAC1BX,EAAUQ,QAAQM,OAASF,EAG3B,MAAMG,QAAYC,EAAIV,OAAOG,GD5CXQ,EAACC,EAAYC,KAEnC,IAAIC,GAAoB,EAGxBF,EAAWG,QAAQC,IAEjB,MAAOC,EAAGC,EAAGX,EAAOC,GAAUQ,EAAiB,KACzChC,EAAOgC,EAAkB,MAGzBG,EAAQC,KAAKC,MAAoB,SAAdD,KAAKE,UAAmBC,SAAS,IAC1DV,EAAIW,YAAc,IAAML,EACxBN,EAAIY,KAAO,aAGXZ,EAAIa,YACJb,EAAIc,UAAY,IAAMR,EACtBN,EAAIe,SAAS5C,EAAMiC,EAAGC,GACtBL,EAAIgB,KAAKZ,EAAGC,EAAGX,EAAOC,GACtBK,EAAIiB,SAGJhB,GAAoB,EAGpB/B,EAAMC,KAIH8B,GACHzB,KCiBEsB,CAASF,EADGf,EAAUQ,QAAQ6B,WAAW,OAIzC,MAAMC,EAAqBvB,EAAIwB,OAAS,EAAIxB,EAAI,GAAGyB,MAAQ,KAGvDF,GAAsBA,IAAuBrC,IAC/CZ,EAAMiD,GACNpC,EAAsBoC,MAMtBG,EAAclC,UAClB,IACEmC,QAAQC,IAAI,oCAAqCC,GACjD,MAAMC,QAAgBC,UAAUC,aAAaC,mBAC7C,IAAIC,EAAmB,KAGvBJ,EAAQxB,QAAQ6B,IACM,eAAhBA,EAAOC,MAAyBD,EAAOE,MAAMC,SAAS,UACxDJ,EAAmBC,EAAOI,YAI9B,MAAMC,EAAc,CAClB9C,MAAO,CACL6C,SAAUL,EAAmB,CAAEO,MAAOP,QAAqBQ,EAC3Db,WAAYA,IAMhB,GAHAF,QAAQC,IAAI,sBAAuBM,GAG/BJ,EAAQa,KAAKR,GAA0B,eAAhBA,EAAOC,MAAwB,CACxD,MAAMQ,QAAeb,UAAUC,aAAaa,aAAaL,GACzDzD,EAAUU,QAAQqD,UAAYF,EAC9BjB,QAAQC,IAAI,mCAAoCC,QAEhDF,QAAQoB,MAAM,gCACdC,MAAM,gCAER,MAAOD,GACPpB,QAAQoB,MAAM,0BAA2BA,GACzCC,MAAM,oFAoBV,OANAC,oBAAU,KACRtB,QAAQC,IAAI,qBA/FEpC,WACd,MAAMS,QAAYiD,SAClBvB,QAAQC,IAAI,0BAEZuB,YAAY,KACV5D,EAAOU,IACN,KA0FHmD,GACA1B,KACC,IAGD2B,IAAAC,cAAA,OAAKC,UAAU,OACbF,IAAAC,cAAA,UAAQC,UAAU,cAClBF,IAAAC,cAAA,OAAKC,UAAU,UACfF,IAAAC,cAAA,UAAQC,UAAU,SAAQ,SACtBF,IAAAC,cAAA,OAAKC,UAAU,gBAAe,gBAEhCF,IAAAC,cAACE,IAAM,CACLC,IAAK1E,EACL2E,OAAO,EACPC,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACbC,KAAM,EACNC,MAAO,EACPC,UAAW,SACXC,OAAQ,EAGRpE,MAAO,MACLqE,SAAU,QACVpE,OAAQ,OACRqE,IAAK,UAIXf,IAAAC,cAAA,UACEG,IAAKxE,EACL0E,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACbC,KAAM,EACNC,MAAO,EACPC,UAAW,SACXC,OAAQ,EAGRpE,MAAO,MACPqE,SAAU,QACVpE,OAAQ,OACRqE,IAAK,UAIRlF,GACCmE,IAAAC,cAAA,OACEK,MAAO,CACLC,SAAU,WACVS,OAAQ,GACRN,KAAM,MACNO,UAAW,mBAEX5D,MAAO,QACP6D,QAAS,YACTC,aAAc,IAEjB,oBACmBtF,GAGrBmE,IAAAC,cAAA,UAAQC,UAAU,gBAAgBkB,QA5EnBC,KACpB,MAAMC,EAAqC,SAArBtF,EAA8B,cAAgB,OACpEC,EAAoBqF,GAEpBjD,EAAYiD,KAwEkD,oBClLlEC,IAASC,OACPxB,IAAAC,cAACD,IAAMyB,WAAU,KACfzB,IAAAC,cAACxE,EAAG,OAENiG,SAASC,eAAe,W","file":"static/js/main.bea54896.chunk.js","sourcesContent":["// ./src/utilities.js\n\nexport const speak = (text) => {\n  const utterance = new SpeechSynthesisUtterance(text);\n  window.speechSynthesis.speak(utterance);\n}\n\nexport const drawRect = (detections, ctx) => {\n  // Variable to keep track of whether any detections are present\n  let detectionsPresent = false;\n\n  // Loop through each prediction\n  detections.forEach(prediction => {\n    // Extract boxes and classes\n    const [x, y, width, height] = prediction['bbox']; \n    const text = prediction['class']; \n\n    // Set styling\n    const color = Math.floor(Math.random()*16777215).toString(16);\n    ctx.strokeStyle = '#' + color\n    ctx.font = '18px Arial';\n\n    // Draw rectangles and text\n    ctx.beginPath();   \n    ctx.fillStyle = '#' + color\n    ctx.fillText(text, x, y);\n    ctx.rect(x, y, width, height); \n    ctx.stroke();\n\n    // Set detectionsPresent to true if any detections are found\n    detectionsPresent = true;\n\n    // Convert text to speech\n    speak(text);\n  });\n\n  // If no detections are present, stop speech synthesis\n  if (!detectionsPresent) {\n    stopSpeech();\n  }\n}\n\n// Function to stop speech synthesis\nconst stopSpeech = () => {\n  window.speechSynthesis.cancel(); // Stop any ongoing speech\n};\n\n","// ./src/App.js\n\n// Import dependencies\nimport React, { useRef, useState, useEffect } from \"react\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as cocossd from \"@tensorflow-models/coco-ssd\";\nimport Webcam from \"react-webcam\";\nimport \"./App.css\";\nimport { drawRect, speak } from \"./utilities\";\n\n//const { SpeechSynthesisUtterance } = window;\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n  const [lastDetectedObject, setLastDetectedObject] = useState(null);\n  const [cameraFacingMode, setCameraFacingMode] = useState(\"environment\"); // Default to back camera\n // const [spokenObject, setSpokenObject] = useState(null); // Flag to track spoken object\n  \n\n  // Main function\n  const runCoco = async () => {\n    const net = await cocossd.load();\n    console.log(\"Handpose model loaded.\");\n    //  Loop and detect hands\n    setInterval(() => {\n      detect(net);\n    }, 10);\n  };\n\n  const detect = async (net) => {\n    // Check data is available\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas height and width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // Make Detections\n      const obj = await net.detect(video);\n\n      // Draw mesh\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drawRect(obj, ctx); \n\n      // Get the name of the first detected object\n      const detectedObjectName = obj.length > 0 ? obj[0].class : null;\n\n      // Speak and update state only if a new object is detected\n      if (detectedObjectName && detectedObjectName !== lastDetectedObject) {\n        speak(detectedObjectName); // Speak the detected object name\n        setLastDetectedObject(detectedObjectName); // Update state with the detected object name\n      }\n    }\n  };\n\n  \n  const startCamera = async (facingMode) => {\n    try {\n      console.log(\"Starting camera with facing mode:\", facingMode);\n      const devices = await navigator.mediaDevices.enumerateDevices();\n      let selectedDeviceId = null;\n  \n      // Find the back camera device ID\n      devices.forEach(device => {\n        if (device.kind === 'videoinput' && device.label.includes('back')) {\n          selectedDeviceId = device.deviceId;\n        }\n      });\n  \n      const constraints = {\n        video: {\n          deviceId: selectedDeviceId ? { exact: selectedDeviceId } : undefined,\n          facingMode: facingMode,\n        },\n      };\n      console.log('Selected Device ID:', selectedDeviceId);\n  \n      // Check if camera devices are available\n      if (devices.some(device => device.kind === 'videoinput')) {\n        const stream = await navigator.mediaDevices.getUserMedia(constraints);\n        webcamRef.current.srcObject = stream;\n        console.log(\"Camera started with facing mode:\", facingMode);\n      } else {\n        console.error(\"No camera devices available.\");\n        alert(\"No camera devices available.\");\n      }\n    } catch (error) {\n      console.error(\"Error accessing camera:\", error);\n      alert(\"Error accessing camera. Please make sure your camera is enabled and try again.\");\n    }\n  };\n  \n  \n  \n   const switchCamera = () => {\n    const newFacingMode = cameraFacingMode === \"user\" ? \"environment\" : \"user\"; // Toggle between front and back camera\n    setCameraFacingMode(newFacingMode); // Update the camera facing mode state\n    \n    startCamera(newFacingMode); // Pass the new facing mode to startCamera functio\n  };\n\n  //useEffect(()=>{runCoco()},[]);\n  useEffect(() => {\n    console.log(\"Running useEffect\");\n    runCoco(); // Load model\n    startCamera(); // Start camera\n  }, []);\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n      <nav className=\"navbar\">\n      <button className=\"login\">LogIn</button>\n          <div className=\"navbar-brand\">Sight Guide</div>\n        </nav>\n        <Webcam\n          ref={webcamRef}\n          muted={true} \n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            // width: 640,\n            // height: 480,\n            width: \"90%\", // Adjusted width for smaller screens\n              maxWidth: \"640px\", // Added maxWidth for larger screens\n              height: \"auto\", // Let height adjust automatically\n              top: \"80px\", // Move the camera box 50px from the top\n          }}\n        />\n\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 8,\n            // width: 640,\n            // height: 480,\n            width: \"90%\", // Adjusted width for smaller screens\n            maxWidth: \"640px\", // Added maxWidth for larger screens\n            height: \"auto\", // Let height adjust automatically\n            top: \"80px\", // Move the camera box 50px from the top\n          }}\n        />\n\n        {lastDetectedObject && (\n          <div\n            style={{\n              position: \"absolute\",\n              bottom: 80,\n              left: \"50%\",\n              transform: \"translateX(-50%)\",\n              // background: \"black\",\n              color: \"black\",\n              padding: \"10px 10px\",\n              borderRadius: 2,\n            }}\n          >\n            Detected Object: {lastDetectedObject}\n          </div>\n        )}\n         <button className=\"detect-button\" onClick={switchCamera}>\n         Switch Camera\n        </button>\n        \n      </header>\n    </div>\n  );\n}\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);"],"sourceRoot":""}